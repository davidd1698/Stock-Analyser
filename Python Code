from datetime import datetime
import lxml
from lxml import html
import requests
import pandas as pd
import numpy as np
import pandas_datareader as web
import matplotlib.pyplot as plt

# Ask for the number of stocks the user wants to preselect
number = None
while number is None:
  try:
    number = int(input("Type the number of stocks you want to preselect: "))
  except ValueError:
    print ("You must type an integer, please try again.")

import datetime

CurrentDate = datetime.date.today()             # dates after this date are in the future and therefore invalid
foundedwallstr = datetime.date(1792, 5, 17)     # dates before this date will be invalid, because the wallstreet wasn't even invented before this date

startdate = None
while startdate is None:
    try:
        startdate = str(input("Enter the start date in YYYY-MM-DD format: "))
        year, month, day = map(int, startdate.split('-'))
        startdate = datetime.date(year, month, day)
        # if the user inputs a higher date than the current
        if startdate > CurrentDate:
            print("Your date can't be in the future, please try again.")
            startdate = None

        # if the user inputs a valid date it's between the current date and the date the wallstreet was founded
        elif foundedwallstr < startdate < CurrentDate:
            print("This date is valid!")
            break

        # if the user inputs a date before there is data
        elif startdate < foundedwallstr:
            print("The stock exchange was in" , startdate, "not even invented, please try again!")
        startdate = None

            # if the user inputs for example letters
    except ValueError:\
        print("You must type a date format, please try again!")
    startdate = None


# Ask for end date
enddate = None
while enddate is None:
  try:
    enddate = str(input("Enter the end date in YYYY-MM-DD format: "))
    year, month, day = map(int, enddate.split('-'))
    enddate = datetime.date(year, month, day)

    # if the user inputs a higher date than the current
    if enddate > CurrentDate:
        print("Your date can't be in the future, please try again.")
        enddate = None

    # if the user inputs a valid date between the start date and the current date
    elif CurrentDate > enddate > startdate:
        print("This date is valid too!")
        break

    # if the user inputs a date before there is data
    elif enddate < foundedwallstr:
        print("The stock exchange was in", startdate, "not even invented, please try again!")
        enddate = None

    # if the user inputs a lower enddate than the startdate
    elif enddate < startdate:
        print("The end date can't be before the start date.")
        enddate = None

    # if the user inputs for example letters
  except ValueError:\
          print("You must type a date format, please try again!")
  enddate = None
    
### end date part
##############################################

# Ask the user to input the tickers
tickers = []
i = 1
while i <= number: 
  try: 
    tick = str(input(f'Enter a {i}th Ticker: ')) 
    tick = tick.upper()
    tickers.append(tick)
    i += 1 
  except ValueError:
    print("Error - you have to enter a string. Try again.") 

# Print the ticker list
print("the ticker list is:", tickers )

# Ask the user to input the risk free rate
riskfree = None
while riskfree is None:
  try:
    riskfree = float(input("Enter the risk free rate in decimals: "))
  except ValueError:
    print ("You must type a float")


# Getting historical stock prices and volume from Yahoo Finance
price_historical = web.get_data_yahoo(tickers,
                           start = startdate,
                           end = enddate)['Adj Close']
                           
volume_historical = web.get_data_yahoo(tickers,
                           start = startdate,
                           end = enddate)['Volume']

# Remove stocks that were not available during this time period and remove the tickers that do not exist
price_historical = price_historical.dropna(axis=1, how='all')

# Computing the log returns
log_ret = np.log(price_historical/price_historical.shift(1))

###################################################################################

# We should add here a part where we get additional info from yahoo finance for each preselected stock and we compute for each stock some performance and risk metrics. Based on this additional information, the user then selects the final sample of stocks he wants to put in his portfolio and the rest of the code does the 3 types of portfolio optimization.

# Set up the request headers that we're going to use, to simulate a request by the Chrome browser.
def get_page(url):  
    headers = {
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',
        'Accept-Encoding': 'gzip, deflate, br',
        'Accept-Language': 'en-US,en;q=0.9',
        'Cache-Control': 'max-age=0',
        'Pragma': 'no-cache',
        'Referrer': 'https://google.com',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36'
    }

    return requests.get(url, headers=headers)

#Ensure that some table rows are found
def parse_rows(table_rows):
    parsed_rows = []

    for table_row in table_rows:
        parsed_row = []
        el = table_row.xpath("./div")

        none_count = 0

        for rs in el:
            try:
                (text,) = rs.xpath('.//span/text()[1]')
                parsed_row.append(text)
            except ValueError:
                parsed_row.append(np.NaN)
                none_count += 1

        if (none_count < 4):
            parsed_rows.append(parsed_row)
            
    return pd.DataFrame(parsed_rows)

# Set the index to the first column: 'Period Ending' and transpose the DataFrame, so that our header contains the account names
def clean_data(df):
    df = df.set_index(0) 
    df = df.transpose() 
    
    # Rename the "Breakdown" column to "Date"
    cols = list(df.columns)
    cols[0] = 'Date'
    df = df.set_axis(cols, axis='columns', inplace=False)
    
    # We convert all columns into float numbers (numeric), except the first column which is the date
    numeric_columns = list(df.columns)[1::] 
    for column_index in range(1, len(df.columns)): 
        df.iloc[:,column_index] = df.iloc[:,column_index].str.replace(',', '') 
        df.iloc[:,column_index] = df.iloc[:,column_index].astype(np.float64) 
        
    return df

def scrape_table(url):
    # Fetch the page that we're going to parse
    page = get_page(url);

    # Parse the page with LXML, so that we can start doing some XPATH queries to extract the data that we want
    tree = html.fromstring(page.content)

    # Fetch all div elements which have class 'D(tbr)'
    table_rows = tree.xpath("//div[contains(@class, 'D(tbr)')]")
    
    # Ensure that some table rows are found
    assert len(table_rows) > 0
    
    df = parse_rows(table_rows)
    df = clean_data(df)
        
    return df

# We scrape data for the balance sheet, the income statement and the cash flow statement 
def scrape(symbol):
    print('Attempting to scrape data for ' + symbol)

    df_balance_sheet = scrape_table('https://finance.yahoo.com/quote/' + symbol + '/balance-sheet?p=' + symbol)
    df_balance_sheet = df_balance_sheet.set_index('Date')

    df_income_statement = scrape_table('https://finance.yahoo.com/quote/' + symbol + '/financials?p=' + symbol)
    df_income_statement = df_income_statement.set_index('Date')
    
    df_cash_flow = scrape_table('https://finance.yahoo.com/quote/' + symbol + '/cash-flow?p=' + symbol)
    df_cash_flow = df_cash_flow.set_index('Date')
    
    # We create a joint table that will gather data from the balance sheet, the income statement and the statement of cash flows for one ticker in the same table
    df_joined = df_balance_sheet \
        .join(df_income_statement, on='Date', how='outer', rsuffix=' - Income Statement') \
        .join(df_cash_flow, on='Date', how='outer', rsuffix=' - Cash Flow') \
        .dropna(axis=1, how='all') \
        .reset_index()
    
    # We add a column that includes the name of the ticker to allow for a better understanding of the results
    df_joined.insert(1, 'Symbol', symbol) 
    
    return df_joined

# We create a new functions that will allow us to scrape data from the all the tickers list that the user inputed before, and run each of tehm through the scrape function we created before
def scrape_multi(tickers):
    return pd.concat([scrape(symbol) for symbol in tickers], sort=False)

# This is the table that will include gather information from the balance sheet, the income statement and the statement of cash flows for all the stocks selected by the user
df_combined = scrape_multi(tickers)

# We ask the program to display all the columns avialable and not hide some of them
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

# We print the table
df_combined



# To allow for some comparison between the stocks, we normalize the adjusted closing prices and plot them 
normalized_price_historical = price_historical.pct_change().dropna()
(normalized_price_historical+1).cumprod().plot(figsize=(15,5))
plt.xlabel('Date')
plt.ylabel('Adjusted Closing Price')
plt.title('Evolution of the Adjusted Closing Price')

#Here we display some additional information about the stock historical closing prices
perc =[.20, .40, .60, .80]
print(price_historical.describe(percentiles = perc))



# To allow for some comparison between the stocks, we normalize the volumes traded and plot them 
normalized_volume_historical = volume_historical.pct_change().dropna()
(normalized_volume_historical+1).cumprod().plot(figsize=(15,5))
plt.xlabel('Date')
plt.ylabel('Adjusted Volume Traded')
plt.title('Evolution of the Adjusted Volume Traded')


##################################################################################


# Computing the variance-covariance matrix
cov_mat = log_ret.cov() * 252 #252 trading days in a year
print(cov_mat)

# number of portfolio to simulate
n_portfolio = 7500

# Creating empty arrays to store portfolio weights, return, risk, and sharpe ratio 
all_weights = np.zeros((n_portfolio, len(price_historical.columns)))
port_returns = np.zeros((n_portfolio))
port_risk = np.zeros((n_portfolio))
sharpe_ratio = np.zeros((n_portfolio))

# Simulating the 7500 portfolios and storing their weights, returns, volatility, sharpe ratio
for i in range(n_portfolio):
  # Generating randon weigths using a uniform distribution
  weights = np.random.uniform(size = len(price_historical.columns))
  weights = weights/np.sum(weights)
  
  # Storing weights 
  all_weights[i,:] = weights
  
  # Storing return
  port_ret = np.sum(log_ret.mean() * weights)
  port_ret = (port_ret + 1) ** 252 - 1
  port_returns[i] = port_ret
  
  # Storing risk
  port_sd = np.sqrt(np.dot(weights.T, np.dot(cov_mat, weights)))
  port_risk[i] = port_sd
  
  # Storing Sharpe Ratio  
  sr = (port_ret - riskfree) / port_sd
  sharpe_ratio[i] = sr

names = price_historical.columns

# Finding the minimum variance portfolio
min_var = all_weights[port_risk.argmin()]
print("The weights of the minimum variance portfolio are:", min_var)

# Finding the tangency portfolio
max_sr = all_weights[sharpe_ratio.argmax()]
print("The weights of the maximum sharpe ratio portfolio are:", max_sr)

# Finding the equally weighted portfolio
eq_weights = []
for i in range(len(weights)):
 eq_weights.append(1/len(weights))
print("The weights of the equally weigthed portfolio are:", eq_weights)

# Finding the maximum return portfolio
max_ret = all_weights[port_ret.argmax()]
print("The weights of the maximum return portfolio are:", max_ret)


# Check if portfolio weights sum to 1
print(sum(min_var), sum(max_sr), sum(eq_weights), sum(max_ret))



################################################################################

# Here we can probably add some graphs and performance and risk metrics for each optimization so that the user can select the optimization he prefers

################################################################################
